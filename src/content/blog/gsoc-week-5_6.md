---
author: Debarghya Datta
pubDatetime: 2024-07-07T05:00:00Z
title: "[GSoC] Week-5/6 Increasing the maaping coverage of Hindi DBpedia"
featured: false
draft: false
tags:
  - gsoc
description: "Work done in the 5th & 6th week of GSoC coding period."
---

This is the fifth and sixth week(24-28th June \& 1-5th July) of the coding period of GSoC where the main aim was to increase the mapping coverage of Hindi Chapter.

## Table of Contents

## Project Updates

**1. Mapping Update**
This week, we made significant progress with our mappings for the Hindi DBpedia chapter. By manually creating high-quality mappings, we increased the mapping coverage from 60% to 80%. This improvement is a major step towards achieving comprehensive and accurate data representation.

**2. Abstract Extractor**
We successfully configured the Abstract Extractor for the Hindi language. This enhancement will allow us to effectively generate abstracts for Hindi entries, enriching our dataset with summarized information.

## Challenges and Solutions

**1. Extraction Framework Issues**
We faced an issue running the extraction framework on my local system. The solution to this problem involves gaining server access, which our mentors have agreed to provide. This will help us bypass local system limitations and ensure smooth operations.

**2. Neural Extraction Framework Implementation**
The implementation details of the neural extraction framework remain unclear. Our mentors need to discuss this further with Tomaso to gain a better understanding and proceed with the implementation.

## Suggestions from Mentors

Our mentors have given us crucial suggestions to improve our project's accessibility and functionality:

- **Deploy the RDFs on a Server:** Making the RDFs accessible to everyone by deploying them on a server will enhance the usability and reach of our data.
- **Setup the SPARQL Endpoint:** Establishing a SPARQL endpoint on a server is essential. This will allow users to query our data efficiently, facilitating better data access and interaction.

## Action Items

**1. Deploy RDFs on a Server**
We will work on deploying the RDFs on a server to make them accessible to all users. This step is crucial for ensuring that our data can be utilized effectively by the community.

**2. Setup the SPARQL Endpoint**
Setting up the SPARQL endpoint on a server is a priority. This will enable users to perform complex queries and retrieve precise information from our dataset.

That's all for this week's update. We're making great strides and are eager to continue building on our progress. Stay tuned for more updates!
